import faiss
import pickle
import requests
import numpy as np
from pathlib import Path
from sentence_transformers import SentenceTransformer

OLLAMA_URL = "http://localhost:11434/api/generate"
MODEL_NAME = "llama3.2:3b-instruct-q6_K"

BASE_DIR = Path(__file__).resolve().parent
INDEX_PATH = BASE_DIR / "index.faiss"
CHUNKS_PATH = BASE_DIR / "chunks.pkl"

# ===== –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å =====
print("üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º FAISS...")
index = faiss.read_index(str(INDEX_PATH))

with open(CHUNKS_PATH, "rb") as f:
    chunks = pickle.load(f)

embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2", device="cpu")

# ===== –ü–æ–∏—Å–∫ =====
def search(query, k=3):
    q_emb = embedder.encode([query])
    q_emb = np.asarray(q_emb, dtype="float32")
    faiss.normalize_L2(q_emb)
    distances, indices = index.search(q_emb, k)
    out = []
    for i in indices[0]:
        if i == -1:
            continue
        out.append(chunks[i])
    return out

# ===== –ó–∞–ø—Ä–æ—Å –∫ Ollama =====
def ask_llama(prompt):
    payload = {
        "model": MODEL_NAME,
        "prompt": prompt,
        "stream": False
    }
    r = requests.post(OLLAMA_URL, json=payload, timeout=120)
    r.raise_for_status()
    data = r.json()
    if "response" not in data:
        raise RuntimeError(f"Unexpected Ollama response keys: {list(data.keys())}")
    return data["response"]

# ===== RAG =====
def answer(question):
    hits = search(question)
    context = "\n\n".join(hits)

    prompt = f"""
–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫.
–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∏–∂–µ.
–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç–∞ –Ω–µ—Ç ‚Äî —Å–∫–∞–∂–∏: "–í –¥–æ–∫—É–º–µ–Ω—Ç–µ –Ω–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏".

–¢–ï–ö–°–¢:
{context}

–í–û–ü–†–û–°:
{question}

–û–¢–í–ï–¢:
"""

    return ask_llama(prompt)

# ===== –ß–∞—Ç =====
while True:
    q = input("\n‚ùì –í–æ–ø—Ä–æ—Å: ")
    if q.lower() in ["exit", "quit"]:
        break

    print("\nüí¨ –û—Ç–≤–µ—Ç:")
    print(answer(q))
